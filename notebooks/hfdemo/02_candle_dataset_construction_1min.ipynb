{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candle Dataset Cleaning\n",
    "\n",
    "After running the first training job on the full dataset, we can see that despite the training loss decreasing, the validation loss is remaining fairly constant. As a potential remedy, we are going to try removing all of the rows from a closed market from the dataset. This will have a few advantages:\n",
    "1. It will drasitcally reduce the size of the data by approximately 55 - 60%, by keeping only the examples that are relevant to the task we need to perform. \n",
    "2. It will ensure that the loss metrics are mearusing the models performnace on market data where trading is occuring. Currently, the loss function is likely dilluted, as so much of the data is just a flat time-series, that the model is likely performing perfectly on these examples, causing the loss metric to be diluted, and likely not allowing a high enough gradient to be built up for the backward pass.\n",
    "\n",
    "## Plan for Cleaning Data \n",
    "\n",
    "1. Remove any rows where the market is closed. We will never be using this in the actual model.\n",
    "2. This should give us a a couple hundred time-series per ticker. We want to create a time-series ID for each continuous time series in the dataset. This will be used as a column ID.\n",
    "3. Then iterate over each ticker. For each ticker:\n",
    " - Use our date indicices, to create a train, validation, and test set for that ticker. Be sure that the date the sets do not slice any time-series (e.g. each of the 3 sets should have a unique set of time-series IDs)\n",
    " - Append eacah of the three sets to a master train, validation, and test set respectively. \n",
    " - These steps will replace the current `select_by_index` usage\n",
    "4. Train the `TimeSeriesPreprocessor` on the train set\n",
    "5. Create the train, validation, and test datasets, using the trained preprocessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Third Party\n",
    "from transformers import (\n",
    "    EarlyStoppingCallback,\n",
    "    PatchTSMixerConfig,\n",
    "    PatchTSMixerForPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First Party\n",
    "from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
    "from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "We want to meticulously craft our examples for each trading day. Our primary focus here is to ensure that the model only is ever asked to forecast into live market data. We need it to understand this type of forecasting, and not be thrown off at all by examples from extended hours trading.\n",
    "\n",
    "There are a few general steps we must take:\n",
    "1. Ensure that all the data from the closed market is removed from the dataset, as this data will never be used in context or in forecasting.\n",
    "2. Ensure that the timestamps are localized to America/New_York, so that we can get accurate date_strings to use for identifying each trading day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m TEST_DATASET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/10s-candles-test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m timestamp_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTRAIN_DATASET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtimestamp_col\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[1;32m     17\u001b[0m     VALID_DATASET,\n\u001b[1;32m     18\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39m[timestamp_col]\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[1;32m     22\u001b[0m     TEST_DATASET,\n\u001b[1;32m     23\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39m[timestamp_col]\n\u001b[1;32m     24\u001b[0m )\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:332\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_length(names, alldata)\n\u001b[1;32m    330\u001b[0m     data \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, (i, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, data_tups)}\n\u001b[0;32m--> 332\u001b[0m     names, date_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_date_conversions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     index, column_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_index(date_data, alldata, names)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index, column_names, date_data\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:880\u001b[0m, in \u001b[0;36mParserBase._do_date_conversions\u001b[0;34m(self, names, data)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_date_conversions\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Sequence[Hashable] \u001b[38;5;241m|\u001b[39m Index, Mapping[Hashable, ArrayLike] \u001b[38;5;241m|\u001b[39m DataFrame]:\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# returns data, columns\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 880\u001b[0m         data, names \u001b[38;5;241m=\u001b[39m \u001b[43m_process_date_conversion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_date_conv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_date_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_date_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m names, data\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:1315\u001b[0m, in \u001b[0;36m_process_date_conversion\u001b[0;34m(data_dict, converter, parse_spec, index_col, index_names, columns, keep_date_col, dtype_backend)\u001b[0m\n\u001b[1;32m   1311\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;66;03m# Pyarrow engine returns Series which we need to convert to\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# numpy array before converter, its a no-op for other parsers\u001b[39;00m\n\u001b[0;32m-> 1315\u001b[0m     data_dict[colspec] \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolspec\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolspec\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1319\u001b[0m     new_name, col, old_names \u001b[38;5;241m=\u001b[39m _try_convert_dates(\n\u001b[1;32m   1320\u001b[0m         converter, colspec, data_dict, orig_names\n\u001b[1;32m   1321\u001b[0m     )\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:1165\u001b[0m, in \u001b[0;36m_make_date_converter.<locals>.converter\u001b[0;34m(col, *date_cols)\u001b[0m\n\u001b[1;32m   1163\u001b[0m str_objs \u001b[38;5;241m=\u001b[39m ensure_object(strs)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstr_objs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_fmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;66;03m# test_usecols_with_parse_dates4\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m str_objs\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1099\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(argc, cache_array)\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43margc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/verb-workspace/tsfm/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:426\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtzconversion.pyx:166\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.tzconversion.tz_localize_to_utc_single\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimezones.pyx:308\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timezones.get_dst_info\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the Dataset from the CSV file\n",
    "DATA_DIR = \"/home/ubuntu/verb-workspace/data\" # set this accordingly to the location of the data\n",
    "DATASET = \"10s-candles-2023-train.csv\"\n",
    "\n",
    "TRAIN_DATASET = f\"{DATA_DIR}/10s-candles-train.csv\"\n",
    "VALID_DATASET = f\"{DATA_DIR}/10s-candles-valid.csv\"\n",
    "TEST_DATASET = f\"{DATA_DIR}/10s-candles-test.csv\"\n",
    "\n",
    "timestamp_col = 't'\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    TRAIN_DATASET,\n",
    "    parse_dates=[timestamp_col]\n",
    ")\n",
    "\n",
    "valid_data = pd.read_csv(\n",
    "    VALID_DATASET,\n",
    "    parse_dates=[timestamp_col]\n",
    ")\n",
    "\n",
    "test_data = pd.read_csv(\n",
    "    TEST_DATASET,\n",
    "    parse_dates=[timestamp_col]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>targ_o</th>\n",
       "      <th>targ_h</th>\n",
       "      <th>targ_l</th>\n",
       "      <th>targ_c</th>\n",
       "      <th>targ_v</th>\n",
       "      <th>ticker</th>\n",
       "      <th>market_extended</th>\n",
       "      <th>market_open</th>\n",
       "      <th>date_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03 05:30:00-05:00</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.80</td>\n",
       "      <td>130.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03 05:30:10-05:00</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.80</td>\n",
       "      <td>130.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 05:30:20-05:00</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.80</td>\n",
       "      <td>130.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-03 05:30:30-05:00</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.80</td>\n",
       "      <td>130.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03 05:30:40-05:00</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.800</td>\n",
       "      <td>130.80</td>\n",
       "      <td>130.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624635</th>\n",
       "      <td>2023-11-17 15:59:10-05:00</td>\n",
       "      <td>249.640</td>\n",
       "      <td>249.645</td>\n",
       "      <td>249.59</td>\n",
       "      <td>249.610</td>\n",
       "      <td>12233.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624636</th>\n",
       "      <td>2023-11-17 15:59:20-05:00</td>\n",
       "      <td>249.605</td>\n",
       "      <td>249.655</td>\n",
       "      <td>249.59</td>\n",
       "      <td>249.635</td>\n",
       "      <td>13620.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624637</th>\n",
       "      <td>2023-11-17 15:59:30-05:00</td>\n",
       "      <td>249.640</td>\n",
       "      <td>249.640</td>\n",
       "      <td>249.59</td>\n",
       "      <td>249.595</td>\n",
       "      <td>9923.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624638</th>\n",
       "      <td>2023-11-17 15:59:40-05:00</td>\n",
       "      <td>249.590</td>\n",
       "      <td>249.630</td>\n",
       "      <td>249.55</td>\n",
       "      <td>249.550</td>\n",
       "      <td>20377.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624639</th>\n",
       "      <td>2023-11-17 15:59:50-05:00</td>\n",
       "      <td>249.550</td>\n",
       "      <td>249.630</td>\n",
       "      <td>249.52</td>\n",
       "      <td>249.590</td>\n",
       "      <td>16515.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5624640 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 t   targ_o   targ_h  targ_l   targ_c  \\\n",
       "0        2023-01-03 05:30:00-05:00  130.800  130.800  130.80  130.800   \n",
       "1        2023-01-03 05:30:10-05:00  130.800  130.800  130.80  130.800   \n",
       "2        2023-01-03 05:30:20-05:00  130.800  130.800  130.80  130.800   \n",
       "3        2023-01-03 05:30:30-05:00  130.800  130.800  130.80  130.800   \n",
       "4        2023-01-03 05:30:40-05:00  130.800  130.800  130.80  130.800   \n",
       "...                            ...      ...      ...     ...      ...   \n",
       "5624635  2023-11-17 15:59:10-05:00  249.640  249.645  249.59  249.610   \n",
       "5624636  2023-11-17 15:59:20-05:00  249.605  249.655  249.59  249.635   \n",
       "5624637  2023-11-17 15:59:30-05:00  249.640  249.640  249.59  249.595   \n",
       "5624638  2023-11-17 15:59:40-05:00  249.590  249.630  249.55  249.550   \n",
       "5624639  2023-11-17 15:59:50-05:00  249.550  249.630  249.52  249.590   \n",
       "\n",
       "          targ_v ticker  market_extended  market_open date_string  \n",
       "0            0.0   AAPL                1            0  2023-01-03  \n",
       "1            0.0   AAPL                1            0  2023-01-03  \n",
       "2            0.0   AAPL                1            0  2023-01-03  \n",
       "3            0.0   AAPL                1            0  2023-01-03  \n",
       "4            0.0   AAPL                1            0  2023-01-03  \n",
       "...          ...    ...              ...          ...         ...  \n",
       "5624635  12233.0      V                0            1  2023-11-17  \n",
       "5624636  13620.0      V                0            1  2023-11-17  \n",
       "5624637   9923.0      V                0            1  2023-11-17  \n",
       "5624638  20377.0      V                0            1  2023-11-17  \n",
       "5624639  16515.0      V                0            1  2023-11-17  \n",
       "\n",
       "[5624640 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1488/1488 [00:42<00:00, 35.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating Validation Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:05<00:00, 35.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating Testing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:05<00:00, 35.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def aggregate_min_candles(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # Set 'date' as the index of the dataframe\n",
    "    # Be sure to make a copy here, so as to not mutate the original\n",
    "    _df = df.set_index(timestamp_col)\n",
    "    \n",
    "    # Group by 'ticker' and 'date_string', and resample the data to 1-minute frequency\n",
    "    groups = _df.groupby(['ticker', 'date_string'])\n",
    "    resampled_groups = []\n",
    "    for (ticker, date_string), _group in tqdm(groups, total=len(groups)):\n",
    "        _group.index = pd.to_datetime(_group.index)\n",
    "        group = _group.resample('1min').agg({\n",
    "            'targ_o': 'first',\n",
    "            'targ_h': 'max',\n",
    "            'targ_l': 'min',\n",
    "            'targ_c': 'last',\n",
    "            'targ_v': 'sum',\n",
    "            'market_extended': 'first',\n",
    "            'market_open': 'first'\n",
    "        })\n",
    "        group['ticker'] = ticker\n",
    "        group['date_string'] = date_string\n",
    "        resampled_groups.append(group)\n",
    "    \n",
    "    # Reset the index to flatten the dataframe\n",
    "    resampled_df = pd.concat(resampled_groups)\n",
    "    resampled_df.reset_index(inplace=True)\n",
    "    return resampled_df\n",
    "    \n",
    "print(\"Aggregating Training Data\")\n",
    "train_data_1min = aggregate_min_candles(train_data)\n",
    "\n",
    "print(\"Aggregating Validation Data\")\n",
    "valid_data_1min = aggregate_min_candles(valid_data)\n",
    "\n",
    "print(\"Aggregating Testing Data\")\n",
    "test_data_1min = aggregate_min_candles(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_data_1min) * 6 == len(train_data)\n",
    "assert len(valid_data_1min) * 6 == len(valid_data)\n",
    "assert len(test_data_1min) * 6 == len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_1_MIN = f\"{DATA_DIR}/1min-candles-train.csv\"\n",
    "VALID_DATASET_1_MIN = f\"{DATA_DIR}/1min-candles-valid.csv\"\n",
    "TEST_DATASET_1_MIN = f\"{DATA_DIR}/1min-candles-test.csv\"\n",
    "\n",
    "train_data_1min.to_csv(TRAIN_DATASET_1_MIN, index=False)\n",
    "valid_data_1min.to_csv(VALID_DATASET_1_MIN, index=False)\n",
    "test_data_1min.to_csv(TEST_DATASET_1_MIN, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-kernel",
   "language": "python",
   "name": "venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
